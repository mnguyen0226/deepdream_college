{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepDream Pretrained ResNet50 on MIT Indoor Scene Recognition\n",
    "- Reference:\n",
    "  - DeepDream Algorithm: https://ai.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What is DeepDream?\n",
    "DeepDream is an artistic algorithm where a pretrained CNN is fed an image and optimized to amplify the features it \"sees\" in the image\n",
    "\n",
    "To achieve this, we can do a gradient ascent usually on the MSE loss constructed over the activations coming from a certain layer. The MSE is constructed between those activations and the all-0s tensor, which would by itself push the highest activations strongest towards zero, but by switching the sign, and doing a gradient ascent instead of descent, we end up amplifying them the most.\n",
    "\n",
    "Depending on the neural network layer the features amplified will either be low level (such as edges, or certain geometric patterns) or high level that heavily depends on the dataset on which the network was pretrained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Coding\n",
    "\n",
    "### 2.1. Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python native libraries\n",
    "import os\n",
    "import enum\n",
    "from collections import namedtuple\n",
    "import argparse\n",
    "import numbers\n",
    "import math\n",
    "\n",
    "# Deep learning related imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "from torch.hub import download_url_to_file\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Prepare Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "    \n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = get_default_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "airport_inside\tcomputerroom\t     inside_subway   pantry\n",
      "artstudio\tconcert_hall\t     jewelleryshop   poolinside\n",
      "auditorium\tcorridor\t     kindergarden    prisoncell\n",
      "bakery\t\tdeli\t\t     kitchen\t     restaurant\n",
      "bar\t\tdentaloffice\t     laboratorywet   restaurant_kitchen\n",
      "bathroom\tdining_room\t     laundromat      shoeshop\n",
      "bedroom\t\televator\t     library\t     stairscase\n",
      "bookstore\tfastfood_restaurant  livingroom      studiomusic\n",
      "bowling\t\tflorist\t\t     lobby\t     subway\n",
      "buffet\t\tgameroom\t     locker_room     toystore\n",
      "casino\t\tgarage\t\t     mall\t     trainstation\n",
      "children_room\tgreenhouse\t     meeting_room    tv_studio\n",
      "church_inside\tgrocerystore\t     movietheater    videostore\n",
      "classroom\tgym\t\t     museum\t     waitingroom\n",
      "cloister\thairsalon\t     nursery\t     warehouse\n",
      "closet\t\thospitalroom\t     office\t     winecellar\n",
      "clothingstore\tinside_bus\t     operating_room\n"
     ]
    }
   ],
   "source": [
    "!ls ../../data/indoorCVPR_09/Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 67 classes: \n",
      " ['videostore', 'warehouse', 'bookstore', 'operating_room', 'meeting_room', 'mall', 'bar', 'auditorium', 'kitchen', 'restaurant', 'fastfood_restaurant', 'gym', 'bathroom', 'subway', 'closet', 'hospitalroom', 'clothingstore', 'casino', 'gameroom', 'restaurant_kitchen', 'nursery', 'grocerystore', 'shoeshop', 'movietheater', 'bowling', 'bedroom', 'corridor', 'poolinside', 'children_room', 'hairsalon', 'dining_room', 'classroom', 'jewelleryshop', 'laboratorywet', 'elevator', 'stairscase', 'concert_hall', 'winecellar', 'tv_studio', 'garage', 'airport_inside', 'florist', 'artstudio', 'prisoncell', 'computerroom', 'library', 'museum', 'waitingroom', 'toystore', 'lobby', 'buffet', 'church_inside', 'deli', 'office', 'dentaloffice', 'bakery', 'cloister', 'studiomusic', 'livingroom', 'kindergarden', 'laundromat', 'pantry', 'inside_subway', 'trainstation', 'locker_room', 'inside_bus', 'greenhouse']\n"
     ]
    }
   ],
   "source": [
    "data_dir = '../../data/indoorCVPR_09/Images'\n",
    "classes = os.listdir(data_dir)\n",
    "print(f\"There are {len(classes)} classes: \\n {classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform images to fit the neural network\n",
    "transformations = transforms.Compose([transforms.Resize((256, 256)), transforms.ToTensor()])\n",
    "\n",
    "dataset = ImageFolder(data_dir, transform = transformations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13000, 2000, 620)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and split dataset\n",
    "random_seed = 42\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "train_set, val_set, test_set = random_split(dataset, [13000, 2000, 620])\n",
    "len(train_set), len(val_set), len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert validation dataset into DataLoader to the model\n",
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl: \n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 25\n",
    "\n",
    "val_dl = DataLoader(val_set, batch_size, num_workers = 4, pin_memory=True)\n",
    "val_dl = DeviceDataLoader(val_dl, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Initialize the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4993a0877a0fc13141152de605da92d17fdc9e6df4645a3134981b6a5853088e"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('deepdream')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
